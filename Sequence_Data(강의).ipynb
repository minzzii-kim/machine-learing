{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF Certificate Category 5 (강의)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minzzii-kim/machine-learing/blob/main/Sequence_Data(%EA%B0%95%EC%9D%98).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCmtzkeGPI2Q"
      },
      "source": [
        "# Category 5\n",
        "\n",
        "Sequence (시계열) 데이터 다루기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSKbgK8PRs5"
      },
      "source": [
        "## 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4QcKvRPSj-"
      },
      "source": [
        "1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPjnA62PXVn"
      },
      "source": [
        "## 순서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T463L0aPPX_n"
      },
      "source": [
        "1. **import**: 필요한 모듈 import\n",
        "2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n",
        "3. **모델링(model)**: 모델을 정의합니다.\n",
        "4. **컴파일(compile)**: 모델을 생성합니다.\n",
        "5. **학습 (fit)**: 모델을 학습시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Hj9c1NPbPu"
      },
      "source": [
        "## 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcvEYUuhPb3f"
      },
      "source": [
        "For this task you will need to train a neural network\n",
        "to predict sunspot activity using the Sunspots.csv\n",
        "provided. \n",
        "\n",
        "Your neural network is expected to have an MAE\n",
        "of at least 20, with top marks going to one with an MAE\n",
        "of around 15. \n",
        "\n",
        "At the bottom is provided some testing\n",
        "code should you want to check before uploading which measures\n",
        "the MAE for you. \n",
        "\n",
        "Strongly recommend you test your model with\n",
        "this to be able to see how it performs.\n",
        "\n",
        "\n",
        "\n",
        "-------------------------------\n",
        "**Sequence(시퀀스)**\n",
        "\n",
        "Sunspots.csv를 사용하여 **태양 흑점 활동(sunspot)을 예측하는 인공신경망을 만듭니다.\n",
        "\n",
        "MAE 오차 기준으로 최소 20이하로 예측할 것을 권장하며, 탑 랭킹에 들려면 MAE 15 근처에 도달해야합니다.\n",
        "\n",
        "아래 주어진 샘플코드는 당신의 모델을 테스트 하는 용도로 활용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C3ewm9XQHgr"
      },
      "source": [
        "-----------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTUdLmS7TE40"
      },
      "source": [
        "## 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqt0NBn4MZl5"
      },
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "\n",
        "from tensorflow.keras.layers import Dense, LSTM, Lambda, Conv1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import Huber"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixYVm16KMZl7"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n",
        "urllib.request.urlretrieve(url, 'sunspots.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LPl4l2AMZl9"
      },
      "source": [
        "## csv 파일로부터 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpW4dyWaMZl-"
      },
      "source": [
        "csv.reader() 함수를 활용합니다.\n",
        "\n",
        "* 첫번째 파라미터에는 file을 , delimiter에는 구분자를 넣어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BamvZ6AvMZl-"
      },
      "source": [
        "with open('sunspots.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    i = 0\n",
        "    for row in reader:\n",
        "        print(row)\n",
        "        i+=1\n",
        "        if i > 10:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxeMEobmNUdo"
      },
      "source": [
        "빈 list를 만들어 줍니다. (sunspots, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dar7eoERNZvF"
      },
      "source": [
        "sunspots = []\n",
        "time_step = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neOkzKg4MZmC"
      },
      "source": [
        "`time_step`에는 **index** 값을, `sunspots`에는 sunspots의 정보를 넣어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0o2dSwVMZmC"
      },
      "source": [
        "with open('sunspots.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    # 첫 줄은 header이므로 skip 합니다.\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        sunspots.append(float(row[2]))\n",
        "        time_step.append(int(row[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKgsyCLRTNgS"
      },
      "source": [
        "sunspots, time_step 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eECxANX-TKaj"
      },
      "source": [
        "sunspots[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npwlA3tSTLgF"
      },
      "source": [
        "time_step[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKs4AbeNfqu"
      },
      "source": [
        "sunspots와 time_step을 `numpy array`로 변환합니다.\n",
        "\n",
        "* 참고: 모델은 list 타입을 받아들이지 못합니다. 따라서, numpy array 로 변환해 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8MrSCu3MZmE"
      },
      "source": [
        "series = np.array(sunspots)\n",
        "time = np.array(time_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fky6hg0yTkDk"
      },
      "source": [
        "series.shape, time.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF0xdyV7Tap3"
      },
      "source": [
        "## 태양의 흑점 활동 (sunspots) 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnTzXWAFMZmG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(time, series)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-YdTCYeMZmc"
      },
      "source": [
        "## Train Set, Validation Set 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRfGcPJET7Dq"
      },
      "source": [
        "3000 인덱스를 기준으로 Train / Validation Set를 분할 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9TsEUONT6nF"
      },
      "source": [
        "split_time = 3000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QXuDIkTMZmd"
      },
      "source": [
        "time_train = time[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "\n",
        "x_train = series[:split_time]\n",
        "x_valid = series[split_time:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amk_ksmDMZmb"
      },
      "source": [
        "## Window Dataset Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9VGhKTIMZmQ"
      },
      "source": [
        "자세한 Dataset 활용법은 [블로그 링크](https://teddylee777.github.io/tensorflow/dataset-batch-window)를 참고해 보시고, 연습해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k161f1YQMZmR"
      },
      "source": [
        "# 윈도우 사이즈\n",
        "window_size=30\n",
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "# 셔플 사이즈\n",
        "shuffle_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfyNoztDMZmb"
      },
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPxvjABJWDro"
      },
      "source": [
        "`train_set`와 `validation_set`를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mLFgMMBMZmg"
      },
      "source": [
        "train_set = windowed_dataset(x_train, \n",
        "                             window_size=window_size, \n",
        "                             batch_size=batch_size,\n",
        "                             shuffle_buffer=shuffle_size)\n",
        "\n",
        "validation_set = windowed_dataset(x_valid, \n",
        "                                  window_size=window_size,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle_buffer=shuffle_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2k1dYQcMZmj"
      },
      "source": [
        "## 모델 정의 (Sequential)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntF-9mrFMZmn"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('https://i.stack.imgur.com/NmYZJ.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJ21qRtMZmp"
      },
      "source": [
        "model = Sequential([\n",
        "    tf.keras.layers.Conv1D(60, kernel_size=5,\n",
        "                         padding=\"causal\",\n",
        "                         activation=\"relu\",\n",
        "                         input_shape=[None, 1]),\n",
        "    tf.keras.layers.LSTM(60, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(60, return_sequences=True),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1bif1TuUl1m"
      },
      "source": [
        "모델의 구조 요약을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgET749LMZmt"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXKGQ3rmMZmv"
      },
      "source": [
        "## 컴파일 (compile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ1ETr6mUuqB"
      },
      "source": [
        "**Optimizer**는 SGD(Stochastic Gradient Descent) 를 사용합니다.\n",
        "\n",
        "* lr(learning_rate): 학습률입니다.\n",
        "* momentum: 모멘텀 (가중치) 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjBesK-SMZmv"
      },
      "source": [
        "optimizer = SGD(lr=1e-5, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYmPEGtZMZmx"
      },
      "source": [
        "**Huber Loss**: MSE와 MAE를 절충한 후버 손실(Huber loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eVR4UNKMZmx"
      },
      "source": [
        "\\begin{split}L_{\\delta}=\\left\\{\\begin{matrix}\n",
        "\\frac{1}{2}(y - \\hat{y})^{2} & if \\left | (y - \\hat{y})  \\right | < \\delta\\\\\n",
        "\\delta ((y - \\hat{y}) - \\frac1 2 \\delta) & otherwise\n",
        "\\end{matrix}\\right.\\end{split}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqIDvyQZMZmy"
      },
      "source": [
        "loss= Huber()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICeNa8kQVDxz"
      },
      "source": [
        "model.compile()시 우리가 튜닝한 **optimizer**와 **loss**를 활용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrbT-cAMZm2"
      },
      "source": [
        "model.compile(loss=loss,\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ0gsuoqSv7z"
      },
      "source": [
        "## ModelCheckpoint: 체크포인트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHmDZ2aSx4O"
      },
      "source": [
        "`val_loss` 기준으로 epoch 마다 최적의 모델을 저장하기 위하여, ModelCheckpoint를 만듭니다.\n",
        "* `checkpoint_path`는 모델이 저장될 파일 명을 설정합니다.\n",
        "* `ModelCheckpoint`을 선언하고, 적절한 옵션 값을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1JJZyg0MZm5"
      },
      "source": [
        "checkpoint_path = 'tmp_checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_mae',\n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1leCk2zKMZm7"
      },
      "source": [
        "## 학습 (fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frdpb5SEMZm7"
      },
      "source": [
        "epochs=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrDA4DzbMZm8"
      },
      "source": [
        "history = model.fit(train_set, \n",
        "                    validation_data=(validation_set), \n",
        "                    epochs=epochs, \n",
        "                    callbacks=[checkpoint],\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzhTOjAninH"
      },
      "source": [
        "## 학습 완료 후 Load Weights (ModelCheckpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLqb_6XrMvdq"
      },
      "source": [
        "학습이 완료된 후에는 반드시 `load_weights`를 해주어야 합니다.\n",
        "\n",
        "그렇지 않으면, 열심히 ModelCheckpoint를 만든 의미가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jO1ucZ9ninH"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t0xRupR1LmK"
      },
      "source": [
        "## 학습 오차에 대한 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwus5OLdFg2t"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8lQCKvaMZnC"
      },
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.arange(1, epochs+1), history.history['loss'])\n",
        "plt.plot(np.arange(1, epochs+1), history.history['val_loss'])\n",
        "plt.title('Loss / Val Loss', fontsize=20)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['loss', 'val_loss'], fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzL9Jv_SMZnE"
      },
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.arange(1, epochs+1), history.history['mae'])\n",
        "plt.plot(np.arange(1, epochs+1), history.history['val_mae'])\n",
        "plt.title('MAE / Val MAE', fontsize=20)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend(['mae', 'val_mae'], fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}