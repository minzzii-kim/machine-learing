{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "TF Certificate  Category 3 (강의) - rps",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minzzii-kim/machine-learing/blob/main/TF_Certificate_Category_3_(%EA%B0%95%EC%9D%98)_rps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCmtzkeGPI2Q"
      },
      "source": [
        "# Category 3\n",
        "\n",
        "Convolution Neural Network (합성곱 신경망)를 활용한 이미지 분류 (Image Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSKbgK8PRs5"
      },
      "source": [
        "## 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4QcKvRPSj-"
      },
      "source": [
        "1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPjnA62PXVn"
      },
      "source": [
        "## 순서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T463L0aPPX_n"
      },
      "source": [
        "1. **import**: 필요한 모듈 import\n",
        "2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n",
        "3. **모델링(model)**: 모델을 정의합니다.\n",
        "4. **컴파일(compile)**: 모델을 생성합니다.\n",
        "5. **학습 (fit)**: 모델을 학습시킵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Hj9c1NPbPu"
      },
      "source": [
        "## 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcvEYUuhPb3f"
      },
      "source": [
        "For this task you will build a classifier for Rock-Paper-Scissors \n",
        "based on the rps dataset.\n",
        "\n",
        "IMPORTANT: Your final layer should be as shown, do not change the\n",
        "provided code, or the tests may fail\n",
        "\n",
        "IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n",
        "So ensure that your input layer is designed accordingly, or the tests\n",
        "may fail. \n",
        "\n",
        "NOTE THAT THIS IS UNLABELLED DATA. \n",
        "You can use the ImageDataGenerator to automatically label it\n",
        "and we have provided some starter code.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "이 작업에서는 Rock-Paper-Scissors에 대한 분류기를 작성합니다.\n",
        "rps 데이터 셋을 기반으로합니다.\n",
        "\n",
        "중요 : 최종 레이어는 그림과 같아야합니다.\n",
        "\n",
        "중요 : 이미지는 3 바이트 150x150의 컬러사진으로 테스트됩니다.\n",
        "따라서 입력 레이어가 그에 따라 설계되었거나 테스트되었는지 확인하십시오.\n",
        "\n",
        "ImageDataGenerator를 사용하여 자동으로 레이블을 지정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C3ewm9XQHgr"
      },
      "source": [
        "-----------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4V-b4CYmJjV"
      },
      "source": [
        "## 필요한 모듈 import 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "480D6-GymGYs"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzV-1NNX1LkV"
      },
      "source": [
        "## Dataset 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOOsLCAj1LkW"
      },
      "source": [
        "가위바위보에 대한 손의 사진을 가지고 `가위`인지, `바위`인지, `보자기`인지 분류하는 `classification` 문제입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g1dTl_q1LkX"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n",
        "urllib.request.urlretrieve(url, 'rps.zip')\n",
        "local_zip = 'rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWULnRzA1Lkd"
      },
      "source": [
        "## STEP 2. Define Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1HQ51J-mT9v"
      },
      "source": [
        "데이터셋의 경로를 지정해 주세요 (root 폴더의 경로를 지정하여야 합니다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFJb6A9z1Lkd"
      },
      "source": [
        "# training dir\n",
        "TRAINING_DIR = \"tmp/rps/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vosdNa0Y1Lkj"
      },
      "source": [
        "## STEP 3. ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrmKimcJ1Lkn"
      },
      "source": [
        "* `rescale`: 이미지의 픽셀 값을 조정\n",
        "* `rotation_range`: 이미지 회전\n",
        "* `width_shift_range`: 가로 방향으로 이동\n",
        "* `height_shift_range`: 세로 방향으로 이동\n",
        "* `shear_range`: 이미지 굴절\n",
        "* `zoom_range`: 이미지 확대\n",
        "* `horizontal_flip`: 횡 방향으로 이미지 반전\n",
        "* `fill_mode`: 이미지를 이동이나 굴절시켰을 때 빈 픽셀 값에 대하여 값을 채우는 방식\n",
        "* `validation_split`: validation set의 구성 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KemaTeRd1Lkp"
      },
      "source": [
        "training_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest', \n",
        "    validation_split=0.2\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ZXhFFK1Lkt"
      },
      "source": [
        "## STEP 4. Make Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKWA55pkmjV3"
      },
      "source": [
        "ImageDataGenerator를 잘 만들어 주었다면, `flow_from_directory`로 이미지를 어떻게 공급해 줄 것인가를 지정해 주어야합니다.\n",
        "\n",
        "* train / validation set 전용 generator를 별도로 정의합니다.\n",
        "* `batch_size`를 정의합니다 (128)\n",
        "* `target_size`를 정의합니다. (150 x 150). 이미지를 알아서 타겟 사이즈 만큼 잘라내어 공급합니다.\n",
        "* `class_mode`는 3개 이상의 클래스인 경우 'categorical' 이진 분류의 경우 `binary`를 지정합니다.\n",
        "* `subset`을 지정합니다. (training / validation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aaAbYk4RqBd"
      },
      "source": [
        "**training_generator**에 대한 `from_from_directory`를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4gbMm121Lk0"
      },
      "source": [
        "training_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=128, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical', \n",
        "                                                          subset='training',\n",
        "                                                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R4eLz3N2KBd"
      },
      "source": [
        "**validation_generator**에 대한 `from_from_directory`를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bAYGsIm1aZG"
      },
      "source": [
        "validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=128, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical',\n",
        "                                                          subset='validation', \n",
        "                                                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEb7eWow2QHJ"
      },
      "source": [
        "504 개의 이미지가 출력되어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piWUxtwz1Lk4"
      },
      "source": [
        "### 시각화 해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jncc3nu1Lk4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_map = {\n",
        "    0: 'Paper',\n",
        "    1: 'Rock', \n",
        "    2: 'Scissors'\n",
        "}\n",
        "\n",
        "print('오리지널 사진 파일')\n",
        "\n",
        "original_datagen = ImageDataGenerator(rescale=1./255)\n",
        "original_generator = original_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                          batch_size=128, \n",
        "                                                          target_size=(150, 150), \n",
        "                                                          class_mode='categorical'\n",
        "                                                         )\n",
        "\n",
        "for x, y in original_generator:\n",
        "    print(x.shape, y.shape)\n",
        "    print(y[0])\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5)\n",
        "    fig.set_size_inches(15, 6)\n",
        "    for i in range(10):\n",
        "        axes[i//5, i%5].imshow(x[i])\n",
        "        axes[i//5, i%5].set_title(class_map[y[i].argmax()], fontsize=15)\n",
        "        axes[i//5, i%5].axis('off')\n",
        "    plt.show()\n",
        "    break\n",
        "    \n",
        "print('Augmentation 적용한 사진 파일')\n",
        "    \n",
        "for x, y in training_generator:\n",
        "    print(x.shape, y.shape)\n",
        "    print(y[0])\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5)\n",
        "    fig.set_size_inches(15, 6)\n",
        "    for i in range(10):\n",
        "        axes[i//5, i%5].imshow(x[i])\n",
        "        axes[i//5, i%5].set_title(class_map[y[i].argmax()], fontsize=15)\n",
        "        axes[i//5, i%5].axis('off')\n",
        "    \n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-Q-MR9r1LlE"
      },
      "source": [
        "### Convolution Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LtXEsae1LlE"
      },
      "source": [
        "**CNN - activation - Pooling** 과정을 통해 이미지 부분 부분의 **주요한 Feature 들을 추출**해 냅니다.\n",
        "\n",
        "CNN을 통해 우리는 다양한 1개의 이미지를 `filter`를 거친 다수의 이미지로 출력합니다.\n",
        "\n",
        "`filter`의 사이즈는 **3 X 3 필터**를 자주 사용합니다\n",
        "\n",
        "또한, 3 X 3 필터를 거친 이미지의 사이즈는 **2px 만큼 사이즈가 줄어듭니다**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNpNKXkm1LlF"
      },
      "source": [
        "[CNN Filter 예시](https://miro.medium.com/max/1070/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7NyN8-81LlG"
      },
      "source": [
        "Image('https://devblogs.nvidia.com/wp-content/uploads/2015/11/fig1.png', width=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQdDTkZ_1LlU"
      },
      "source": [
        "## 이미지 특성 추출: Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Jen2_11LlR"
      },
      "source": [
        "for x, y in original_generator:\n",
        "    pic = x[:5]\n",
        "    break\n",
        "    \n",
        "plt.imshow(pic[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq_WZZ8P1LlV"
      },
      "source": [
        "conv2d = Conv2D(64, (3, 3), input_shape=(150, 150, 3))\n",
        "conv2d_activation = Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdGaYn091Llb"
      },
      "source": [
        "fig, axes = plt.subplots(8, 8)\n",
        "fig.set_size_inches(16, 16)\n",
        "for i in range(64):\n",
        "    axes[i//8, i%8].imshow(conv2d(pic)[0,:,:,i], cmap='gray')\n",
        "    axes[i//8, i%8].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyPRztY21Llo"
      },
      "source": [
        "## 이미지 특성 추출: MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHdjvdnw1Llo"
      },
      "source": [
        "fig, axes = plt.subplots(8, 8)\n",
        "fig.set_size_inches(16, 16)\n",
        "for i in range(64):\n",
        "    axes[i//8, i%8].imshow(MaxPooling2D(2, 2)(conv2d(pic))[0, :, :, i], cmap='gray')\n",
        "    axes[i//8, i%8].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YekA1ZxNpazk"
      },
      "source": [
        "## 단계별 특성 추출 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oLNbjvfqpJc"
      },
      "source": [
        "conv1 = Conv2D(64, (3, 3), input_shape=(150, 150, 3))(pic)\n",
        "max1 = MaxPooling2D(2, 2)(conv1)\n",
        "conv2 = Conv2D(64, (3, 3))(max1)\n",
        "max2 = MaxPooling2D(2, 2)(conv2)\n",
        "conv3 = Conv2D(64, (3, 3))(max2)\n",
        "max3 = MaxPooling2D(2, 2)(conv3)\n",
        "\n",
        "fig, axes = plt.subplots(4, 1)\n",
        "fig.set_size_inches(6, 12)\n",
        "axes[0].set_title('Original', fontsize=20)\n",
        "axes[0].imshow(pic[0])\n",
        "axes[0].axis('off')\n",
        "axes[1].set_title('Round 1', fontsize=20)\n",
        "axes[1].imshow( conv1[0, :, :, 0], cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[2].set_title('Round 2', fontsize=20)\n",
        "axes[2].imshow( conv2[0, :, :, 0], cmap='gray')\n",
        "axes[2].axis('off')\n",
        "axes[3].set_title('Round 3', fontsize=20)\n",
        "axes[3].imshow( conv3[0, :, :, 0], cmap='gray')\n",
        "axes[3].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfIjG32j1Lls"
      },
      "source": [
        "## 모델 정의 (Sequential)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwj8Q1ZR1Llt"
      },
      "source": [
        "model = Sequential([\n",
        "    # Conv2D, MaxPooling2D 조합으로 층을 쌓습니다. 첫번째 입력층의 input_shape은 (150, 150, 3)으로 지정합니다.\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2), \n",
        "    # 2D -> 1D로 변환을 위하여 Flatten 합니다.\n",
        "    Flatten(), \n",
        "    # 과적합 방지를 위하여 Dropout을 적용합니다.\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    # Classification을 위한 Softmax \n",
        "    # 출력층의 갯수는 클래스의 갯수와 동일하게 맞춰줍니다 (3개), activation도 잊지마세요!\n",
        "    Dense(3, activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw_G-lkR1Llv"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa3EWM7AobvV"
      },
      "source": [
        "## 컴파일 (compile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHQ1abHXK8e9"
      },
      "source": [
        "1. `optimizer`는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.\n",
        "2. `loss`설정\n",
        "  * 출력층 activation이 `sigmoid` 인 경우: `binary_crossentropy`\n",
        "  * 출력층 activation이 `softmax` 인 경우: \n",
        "    * 원핫인코딩(O): `categorical_crossentropy`\n",
        "    * 원핫인코딩(X): `sparse_categorical_crossentropy`)\n",
        "3. 참고: `ImageDataGenerator`는 자동으로 Label을 **원핫인코딩(one-hot encoding)** 해줍니다.\n",
        "4. `metrics`를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzw3sIaB1Ll0"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ0gsuoqSv7z"
      },
      "source": [
        "## ModelCheckpoint: 체크포인트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHmDZ2aSx4O"
      },
      "source": [
        "`val_loss` 기준으로 epoch 마다 최적의 모델을 저장하기 위하여, ModelCheckpoint를 만듭니다.\n",
        "* `checkpoint_path`는 모델이 저장될 파일 명을 설정합니다.\n",
        "* `ModelCheckpoint`을 선언하고, 적절한 옵션 값을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdgjHzXkoX1b"
      },
      "source": [
        "checkpoint_path = \"tmp_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820Nfvw81Ll5"
      },
      "source": [
        "## 학습 (fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7WWv95oIqM"
      },
      "source": [
        "epochs=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifj14vP71LmA"
      },
      "source": [
        "history = model.fit(training_generator, \n",
        "                    validation_data=(validation_generator),\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[checkpoint],\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzhTOjAninH"
      },
      "source": [
        "## 학습 완료 후 Load Weights (ModelCheckpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLqb_6XrMvdq"
      },
      "source": [
        "학습이 완료된 후에는 반드시 `load_weights`를 해주어야 합니다.\n",
        "\n",
        "그렇지 않으면, 열심히 ModelCheckpoint를 만든 의미가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jO1ucZ9ninH"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t0xRupR1LmK"
      },
      "source": [
        "## 학습 오차에 대한 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r02iNGd1LmL"
      },
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.arange(1, epochs+1), history.history['acc'])\n",
        "plt.plot(np.arange(1, epochs+1), history.history['loss'])\n",
        "plt.title('Acc / Loss', fontsize=20)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc / Loss')\n",
        "plt.legend(['acc', 'loss'], fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}